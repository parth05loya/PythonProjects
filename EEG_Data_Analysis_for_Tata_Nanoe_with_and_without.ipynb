{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njlC39EfIcJm"
      },
      "outputs": [],
      "source": [
        "# === 1. Install & Imports ===\n",
        "!pip install --quiet mne pyxdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mne\n",
        "import pyxdf\n",
        "from mne.time_frequency import psd_array_welch\n",
        "\n",
        "# === 2. Helper Functions ===\n",
        "\n",
        "def load_eeg_from_xdf(path):\n",
        "    streams, _ = pyxdf.load_xdf(path)\n",
        "    # Pick the stream whose type is exactly 'EEG'\n",
        "    eegs = [s for s in streams if s['info']['type'][0] == 'EEG']\n",
        "    if not eegs:\n",
        "        raise ValueError(f\"No EEG stream in {os.path.basename(path)}\")\n",
        "    e = eegs[0]\n",
        "    data = np.array(e['time_series']).T\n",
        "    sfreq = float(e['info']['nominal_srate'][0])\n",
        "    chs = [ch['label'][0] for ch in e['info']['desc'][0]['channels'][0]['channel']]\n",
        "    info = mne.create_info(ch_names=chs, sfreq=sfreq, ch_types=['eeg']*len(chs))\n",
        "    return mne.io.RawArray(data, info)\n",
        "\n",
        "def preprocess(raw):\n",
        "    sfreq = raw.info['sfreq']\n",
        "    # Check Nyquist: need sfreq/2 > 40 to do a 1–40 Hz bandpass\n",
        "    if sfreq / 2 <= 40:\n",
        "        print(f\"⚠ Sampling rate {sfreq:.1f} Hz too low for 40 Hz filter; skipping this file.\")\n",
        "        return None\n",
        "    raw.filter(1., 40., fir_design='firwin')\n",
        "    raw.set_eeg_reference('average', projection=True)\n",
        "    raw.interpolate_bads()\n",
        "    return raw\n",
        "\n",
        "def compute_band_power_from_data(data, sfreq):\n",
        "    # Drop NaN or flat channels\n",
        "    mask = (~np.isnan(data).any(axis=1)) & (data.std(axis=1) > 1e-12)\n",
        "    data = data[mask]\n",
        "    if data.size == 0:\n",
        "        return dict.fromkeys(['delta','theta','alpha','beta','gamma'], np.nan)\n",
        "    # Remove DC offset\n",
        "    data = data - data.mean(axis=1, keepdims=True)\n",
        "    n_fft = min(2048, data.shape[1])\n",
        "    psds, freqs = psd_array_welch(data, sfreq=sfreq, fmin=1, fmax=40, n_fft=n_fft)\n",
        "    return {\n",
        "        'delta': psds[:, (freqs>=1)  & (freqs<4)].mean(),\n",
        "        'theta': psds[:, (freqs>=4)  & (freqs<8)].mean(),\n",
        "        'alpha': psds[:, (freqs>=8)  & (freqs<13)].mean(),\n",
        "        'beta' : psds[:, (freqs>=13) & (freqs<30)].mean(),\n",
        "        'gamma': psds[:, (freqs>=30)].mean()\n",
        "    }\n",
        "\n",
        "# === 3. Process participant P02 ===\n",
        "\n",
        "participant = 'P04'\n",
        "base_path   = f\"/content/nanoe_eeg_data/{participant}\"\n",
        "results     = []\n",
        "\n",
        "# 3a) Eye‐closure & Eye‐opening (session‐level)\n",
        "for task in ['eye_closure','eye_opening']:\n",
        "    for cond in ['with','without']:\n",
        "        fpath = os.path.join(base_path, f\"{task}_{cond}.xdf\")\n",
        "        if not os.path.isfile(fpath):\n",
        "            print(\"Missing:\", fpath)\n",
        "            continue\n",
        "        raw = load_eeg_from_xdf(fpath)\n",
        "        raw = preprocess(raw)\n",
        "        if raw is None:\n",
        "            continue\n",
        "        bp = compute_band_power_from_data(raw.get_data(), raw.info['sfreq'])\n",
        "        bp.update({\n",
        "            'participant': participant,\n",
        "            'task': task,\n",
        "            'condition': cond,\n",
        "            'event': None\n",
        "        })\n",
        "        results.append(bp)\n",
        "\n",
        "# 3b) Driving (event‐wise on full recording)\n",
        "for cond in ['with','without']:\n",
        "    fpath = os.path.join(base_path, f\"driving_{cond}.xdf\")\n",
        "    if not os.path.isfile(fpath):\n",
        "        continue\n",
        "\n",
        "    # 1) Load & preprocess full raw\n",
        "    raw_full = load_eeg_from_xdf(fpath)\n",
        "    raw_full = preprocess(raw_full)\n",
        "    if raw_full is None:\n",
        "        continue\n",
        "    sfreq   = raw_full.info['sfreq']\n",
        "    streams, _ = pyxdf.load_xdf(fpath)\n",
        "\n",
        "    bp_full = compute_band_power_from_data(raw_full.get_data(picks='eeg'), sfreq)\n",
        "    bp_full.update({\n",
        "        'participant': participant,\n",
        "        'task':       'driving',\n",
        "        'condition':  cond,\n",
        "        'event':      'entire recording'\n",
        "    })\n",
        "    results.append(bp_full)\n",
        "\n",
        "    # 2) Align all marker streams to EEG\n",
        "    eeg_stream = next(s for s in streams if s['info']['type'][0]=='EEG')\n",
        "    eeg_ts     = np.array(eeg_stream['time_stamps'])\n",
        "    eeg_start  = eeg_ts[0]\n",
        "\n",
        "    marker_streams = [s for s in streams if s['info']['type'][0]=='Markers']\n",
        "    all_ts  = np.concatenate([s['time_stamps']    for s in marker_streams])\n",
        "    all_lbl = np.concatenate([[v[0] for v in s['time_series']] for s in marker_streams])\n",
        "    rel_t   = all_ts - eeg_start\n",
        "    samples = np.round(rel_t * sfreq).astype(int)\n",
        "\n",
        "    # 3) For each event label, collect its sample indices (sorted)\n",
        "    label_to_samples = {}\n",
        "    for samp, lbl in zip(samples, all_lbl):\n",
        "        if 0 <= samp < raw_full.n_times:\n",
        "            label_to_samples.setdefault(lbl, []).append(samp)\n",
        "\n",
        "    # 4) For each label, form successive intervals & compute segment-power\n",
        "    for lbl, s_list in label_to_samples.items():\n",
        "        s_list = sorted(s_list)\n",
        "        segment_powers = []\n",
        "        for start, end in zip(s_list, s_list[1:]):\n",
        "            # skip if too short\n",
        "            if end - start < int(sfreq*0.5):  # e.g. require at least 0.5 s\n",
        "                continue\n",
        "            seg = raw_full.get_data(picks='eeg')[:, start:end]\n",
        "            bp_seg = compute_band_power_from_data(seg, sfreq)\n",
        "            segment_powers.append(bp_seg)\n",
        "\n",
        "        # 5) Average across all segments for this label\n",
        "        if not segment_powers:\n",
        "            avg_bp = dict.fromkeys(['delta','theta','alpha','beta','gamma'], np.nan)\n",
        "        else:\n",
        "            avg_bp = {}\n",
        "            for band in ['delta','theta','alpha','beta','gamma']:\n",
        "                avg_bp[band] = np.nanmean([seg[band] for seg in segment_powers])\n",
        "\n",
        "        # 6) Add one row for this label\n",
        "        avg_bp.update({\n",
        "            'participant': participant,\n",
        "            'task':       'driving',\n",
        "            'condition':  cond,\n",
        "            'event':      lbl\n",
        "        })\n",
        "        results.append(avg_bp)\n",
        "\n",
        "# === 4. Aggregate & Save ===\n",
        "\n",
        "df = pd.DataFrame(results)[\n",
        "    ['delta','theta','alpha','beta','gamma','participant','task','condition','event']\n",
        "]\n",
        "print(\"\\nFinal event‐wise band‐power table for\", participant)\n",
        "print(df)\n",
        "df.to_csv(f\"{participant}_eventwise_band_power.csv\", index=False)\n",
        "print(\"\\nSaved to\", f\"{participant}_eventwise_band_power.csv\")\n"
      ]
    }
  ]
}